---
layout: default
---

# Ting Han 

<!--<em>Curriculum Vitae: </em><a href="/files/CV_new.pdf" >target="_blank">PDF</a>  <small>(August, 2018)</small> <br>-->
Researcher<br>
Email: firstname.lastname@aist.go.jp <br><!---| <a href="mailto:dhawal.joharapurkar@gmail.com">dhawal.joharapurkar@gmail.com</a> <br>-->
<!--<em>Office: </em>UHG, C-5-204<br>-->
<!-- <p><a href="http://doodle.com/dhawaljoh" target="_blank">Meet me!</a> | <a href="http://flask.io/yoUm1" target="_blank">Assign me a task!</a> (please let me know you've added something!)</p> -->
<!--<hr width="600px">-->

<!--<hr style="height:10pt; visibility:hidden;" />-->

## About Me

I'm a researcher at <a href="https://www.aist.go.jp/waterfront/index_en.html" target="_blank"> National Institue of Advanced Industrial Science and Technology (AIST)</a>. I received my PhD from <a href="https://www.uni-bielefeld.de" target="_blank"> Bielefeld University</a>, advised by Prof. Dr. David Schlangen.  I was also a member of the <a href="http://www.cit-ec.de" target="_blank"> Cognitive Interaction Technology Center of Excellence (CITEC)</a> graduate school. Previously I earned a M.S. in computer vision and B.S. in computer science, both from Lanzhou University in China.


<!--<a href="http://www.dsg-bielefeld.de/dsg_wp/" target="_blank"><img src="images/dsglogo.png" alt="dsg" style="width:220px;" align="right"></a>-->


I’m interested in enabling AIs to understand natural human communications. My PhD research focuses on exploring how natural language informs the interpretation of co-verbal gestures. Find more about the work I've done on my  <a href="/research/" target="_blank">research page</a>. <br> <br>

<b>Keywords:</b> Multimodal interactions, natural language processing, co-verbal gestures

## Publications
1. **Learning to Describe Multimodally from Parallel Unimodal Data? A Pilot Study on Verbal and Sketched Object Descriptions**.   <u>Ting Han</u>,  Sina Zarrieß, Kazunori Komatani, and David Schlangen.  *Proceedings of the 22nd Workshop on the Semantics and Pragmatics of Dialogue (AixDial)*, November 8-10th 2018, Aix-en-Provence (France) [PDF](files/papers/semdial18.pdf)

1.  **Learning to Interpret and Apply Multimodal Descriptions**. <u>Ting Han</u>. *Bielefeld University*, 2018.

1. **A Corpus of Natural Multimodal Spatial Scene Descriptions**.  <u>Ting Han</u> and David Schlangen. *The 11th edition of the Language Resources and Evaluation Conference (LREC18)*, 7-12 May 2018, Miyazaki, Japan. [pdf](files/papers/lrec18.pdf)  [bib](bib/Hanlrec18.txt)

1. **Placing Objects in Gesture Space: Toward Real-Time Understanding of Spatial Descriptions**. <u>Ting Han</u>, Casey Kennington and David Schlangen.  *The thrity-second AAAI conference on artificial intelligence (AAAI18), Feburary 2-7, New Orleans, Louisiana, USA, 2018*. [pdf](files/papers/aaai18.pdf)   [bib](bib/HanEtalaaai18.txt) 

1.  **Draw and Tell: Multimodal Descriptions Outperform Verbal- or Sketch-Only Descriptions in an Image Retrieving Task**.  <u>Ting Han</u> and David Schlangen. *Inproceedings of  the 8th international joint conference of natural language processing (IJCNLP17), Taipei, Taiwan, 2017*.  [PUB](https://pub.uni-bielefeld.de/publication/2913598)

1.  **Natural Language Informs the Interpretation of Iconic Gestures: A Computational Approach**. <u>Ting Han</u>, Julian Hough, and David Schlangen. *Inproceedings of the 8th international joint conference of natural language processing (IJCNLP17), Taipei, Taiwan, 2017*.  [PUB](https://pub.uni-bielefeld.de/publication/2913599)


1. **Temporal Alignment Using the Incremental Unit Framework**. Casey Kenninton,  <u>Ting Han</u>, and David Schlangen, *Proceedings of 19th ACM International Conference on Multimodal Interaction, Glasgow, Scotland, November 13-17th, 2017 (ICMI17).*   [PUB](https://pub.uni-bielefeld.de/publication/2913600)

3. **Grounding Language by Continuous Observation of Instruction Following**.  <u>Ting Han</u> and David Schlangen, *Proceedings of the Annual Meeting of the European Chapter of the Association for Computational Linguistics (EACL), Valencia: 491-496, 2017*. [PUB](https://pub.uni-bielefeld.de/publication/2908812)

4. **Building and Applying Perceptually-Grounded Representations of Multimodal Scene Descriptions**. <u>Ting Han</u>, Casey Kennington, and David Schlangen, *Proceedings of the 19th SemDial Workshop on the Semantics and Pragmatics of Dialogue (goDIAL)* 2015. [PUB](https://pub.uni-bielefeld.de/publication/2758943)

5. **A Corpus of Virtual Pointing Gestures**. <u>Ting Han</u>, Spyros Kousidis, and David Schlangen, *Presented at the REFNET Workshop on Computational and Psychological Models of Reference Comprehension and Production, Edinburgh* 2014. [Poster] [PUB](https://pub.uni-bielefeld.de/publication/2685979)

6. **Towards Automatic Understanding of ‘Virtual Pointing’ in Interaction**.  <u>Ting Han</u>, Spyros Kousidis, and David Schlangen, *Proceedings of the 18th SemDial Workshop on the Semantics and Pragmatics of Dialogue (DialWatt), Posters. Herriot-Watt University; 2014: 188-190*. [poster] [PUB](https://pub.uni-bielefeld.de/publication/2685950)

7. **A Fast Dark Channel Prior-Based Depth Map Approximation Method for Dehazing Single Images**. <u>Ting Han</u> and Yi Wan. *In International Conference on Information Science and Technology (ICIST), 2013, pages 1355–1359.* [PUB](http://ieeexplore.ieee.org/abstract/document/6747789/) 


